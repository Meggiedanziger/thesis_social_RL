scale_y_continuous(breaks = seq(0.1, 0.9, 0.2)) +
scale_x_continuous(breaks = seq(0.1, 0.9, 0.2)) +
xlab("Simulated \alpha values excluder") +
ylab("Estimated \alpha values excluder") +
theme_classic()
recovery_alpha_ex
recovery_alpha_ex <-
ggplot(aes(x = alpha_ex_sim, y = alpha_ex_fit, color = alpha_ex_sim), data = modelfit) +
geom_point(size = 2, alpha = 0.6) +
geom_smooth(method = "glm", color = "darkgrey", se = F, fill = "red", alpha = 0.2) +
scale_color_gradient(low = "blue", high = "red", "Simulated alpha \nvalues excluder") +
scale_y_continuous(breaks = seq(0.1, 0.9, 0.2)) +
scale_x_continuous(breaks = seq(0.1, 0.9, 0.2)) +
xlab("Simulated expression(alpha) values excluder") +
ylab("Estimated alpha values excluder") +
theme_classic()
recovery_alpha_ex
recovery_alpha_ex <-
ggplot(aes(x = alpha_ex_sim, y = alpha_ex_fit, color = alpha_ex_sim), data = modelfit) +
geom_point(size = 2, alpha = 0.6) +
geom_smooth(method = "glm", color = "darkgrey", se = F, fill = "red", alpha = 0.2) +
scale_color_gradient(low = "blue", high = "red", "Simulated alpha \nvalues excluder") +
scale_y_continuous(breaks = seq(0.1, 0.9, 0.2)) +
scale_x_continuous(breaks = seq(0.1, 0.9, 0.2)) +
xlab("Simulated \expression(alpha) values excluder") +
ylab("Estimated alpha values excluder") +
theme_classic()
corr_alpha_in <- cor.test(modelfit$alpha_in_sim, modelfit$alpha_in_fit)
recovery_alpha_in <-
ggplot(aes(x = alpha_in_sim, y = alpha_in_fit, color = alpha_in_sim), data = modelfit) +
geom_point(size = 2, alpha = 0.6) +
geom_smooth(method = "glm", color = "darkgrey", se = F, fill = "red", alpha = 0.2) +
scale_color_gradient(low = "blue", high = "red") +
scale_y_continuous(breaks = seq(0.1, 0.9, 0.2)) +
scale_x_continuous(breaks = seq(0.1, 0.9, 0.2)) +
xlab("Simulated alpha values includer") +
ylab("Estimated alpha values includer") +
theme_classic()
corr_alpha_in
recovery_alpha_in
corr_beta <- cor.test(modelfit$beta_sim, modelfit$beta_fit)
recovery_beta <-
ggplot(aes(x = beta_sim, y = beta_fit, color = beta_sim), data = modelfit) +
geom_point(size = 2, alpha = 0.6) +
geom_smooth(method = "glm", color = "darkgrey", se = F, fill = "red", alpha = 0.2) +
scale_color_gradient(low = "blue", high = "red") +
scale_y_continuous(breaks = seq(0.1, 0.9, 0.2)) +
scale_x_continuous(breaks = seq(0.1, 0.9, 0.2)) +
xlab("Simulated beta values") +
ylab("Estimated beta values") +
theme_classic()
corr_beta
recovery_beta
rm(list = ls()) # delete workspace
setwd("~/Dropbox/___MA/social_RL_git/thesis_social_RL")
getwd()
library(tidyverse)
library(reshape)
num = 125
subj = c(1:125)
#determine prediction of the model with best parameter estimates
cchoice      <- array(0, c(125, 8, 30))
R            <- array(0, c(125, 8, 30))
Prob         <- array(0, c(125, 8, 30))
Feed         <- array(0, c(125, 8, 30))
Feed_c       <- array(0, c(125, 8, 30))
Feed_i       <- array(0, c(125, 8, 30))
Prob_correct <- array(0, c(125, 8, 30))
PE <- Q_all  <- array(0, c(125, 8, 30))
id       <- c(1:125)
alpha_ex <- rep(seq(1, 9, 2), each = 1)/10
alpha_in <- rep(seq(1, 9, 2), each = 5)/10
beta     <- rep(seq(1, 9, 2), each = 25)/10
FIT <- cbind(id, alpha_ex , alpha_in, beta)
for (id in subj) {
alpha_ex <- FIT[id, 2];
alpha_in <- FIT[id, 3];
beta     <- FIT[id, 4];
for (block in c(1:8)) {
Q    <- matrix(0, 1, 2) # 1 row, 4 col
PROB <- matrix(0, 1, 2)
for (trial in c(1:30)) {
for (j in c(1:2)) { # options
PROB[1, j] <- exp(beta*Q[1, j]) / (exp(beta*Q[1, 1]) + exp(beta*Q[1, 2]))
choice     <- c(j, 3-j)
P          <-   c(PROB[1, j], 1-PROB[1, j])
cchoice [id, block, trial] <- sample(choice, 1, replace = FALSE, prob = P)
feedback <- c(-10, 10)
if (cchoice [id, block, trial] == 2) {#good option --> includer
rew_prob <- c(.25, .75)
R [id, block, trial] <- sample(feedback, 1, replace = FALSE, prob = rew_prob)
Q[1,cchoice[id,block,trial] ] <- Q[1,cchoice[id,block,trial] ] + alpha_in * (R[id,block,trial] - Q[1,cchoice[id,block,trial] ]);
}
else {#bad option --> excluder
rew_prob <- c(.75, .25)
R[id, block, trial] <- sample(feedback, 1, replace = FALSE, prob = rew_prob)
Q[1,cchoice[id,block,trial] ] <- Q[1,cchoice[id,block,trial] ] + alpha_ex * (R[id,block,trial] - Q[1,cchoice[id,block,trial] ]);
}
#if (cchoice[id,block,trial]  == 2) {
#  Q[1,1] <- -Q[1,2];
#}
#else  {
#  Q[1,2] <- -Q[1,1]; #symmetrisches Update der Q values
#}
}
}
}
}
R_ <- melt(R)
C_ <- melt(cchoice)
merged_dat <- merge(C_, R_, by = c("X1", "X2", "X3"))
names(merged_dat)[1] <- "id"
names(merged_dat)[2] <- "block"
names(merged_dat)[3] <- "trial"
names(merged_dat)[4] <- "chosen_option"
names(merged_dat)[5] <- "feedback"
merged_dat$chosen_option <- merged_dat$chosen_option - 1
acc <- tapply(merged_dat$chosen_option, merged_dat$id, mean)
plot(acc)
sim_data <- merged_dat
sim_data <- write.table(merged_dat, file = "ex_ante_simulation_2lrates_8blocks_30trials.txt",
row.names = FALSE, col.names = FALSE)
params_exante <- write.table(FIT, file = "ex_ante_simulation_parameters_2lrates_8blocks_30trials.txt",
row.names = FALSE, col.names = FALSE)
rm(list = ls()) # delete workspace
setwd("~/Dropbox/___MA/social_RL_git/thesis_social_RL")
getwd()
library(tidyverse)
library(reshape)
num = 250
subj = c(1:250)
#determine prediction of the model with best parameter estimates
cchoice      <- array(0, c(250, 8, 30))
R            <- array(0, c(250, 8, 30))
Prob         <- array(0, c(250, 8, 30))
Feed         <- array(0, c(250, 8, 30))
Feed_c       <- array(0, c(250, 8, 30))
Feed_i       <- array(0, c(250, 8, 30))
Prob_correct <- array(0, c(250, 8, 30))
PE <- Q_all  <- array(0, c(250, 8, 30))
id     <- c(1:250)
temp   <- rep(seq(1, 9, 2), each = 5)/10
lrate  <- rep(seq(1, 9, 2), each = 1)/10
weight <- rep(seq(from = -9, to = 9, 2), each = 25)/10
FIT <- cbind(id, lrate , temp, weight)
View(FIT)
for (id in subj) {
alpha  <- FIT[id, 2];
beta   <- FIT[id, 3];
weight <- FIT[id, 4];
for (block in c(1:8)) {
Q    <- matrix(0, 1, 2) # 1 row, 2 columns
PROB <- matrix(0, 1, 2)
for (trial in c(1:30)) {
for (j in c(1:2)) { # options
PROB[1, j] <- exp(beta*Q[1, j]) / (exp(beta*Q[1, 1]) + exp(beta*Q[1, 2]))
choice     <- c(j, 3-j)
P          <-   c(PROB[1, j], 1-PROB[1, j])
cchoice [id, block, trial] <- sample(choice, 1, replace = FALSE, prob = P)
}
feedback <- c(-10, 10)
if (cchoice [id, block, trial] == 2) {
rew_prob <- c(.25, .75)
R [id, block, trial] <- sample(feedback, 1, replace = FALSE, prob = rew_prob)
}
else {
rew_prob <- c(.75, .25)
R[id, block, trial] <- sample(feedback, 1, replace = FALSE, prob = rew_prob)
}
Q[1,cchoice[id,block,trial]] <- Q[1,cchoice[id,block,trial]] + alpha * ((weight * R[id,block,trial]) - Q[1,cchoice[id,block,trial]]);
#if (cchoice[id,block,trial]  == 2) {
#  Q[1,1] <- -Q[1,2];
#}
#else  {
#  Q[1,2] <- -Q[1,1]; #symmetrisches Update der Q values
#}
}
}
}
R_ <- melt(R)
C_ <- melt(cchoice)
merged_dat <- merge(C_, R_, by = c("X1", "X2", "X3"))
names(merged_dat)[1] <- "id"
names(merged_dat)[2] <- "block"
names(merged_dat)[3] <- "trial"
names(merged_dat)[4] <- "chosen_option"
names(merged_dat)[5] <- "feedback"
merged_dat$chosen_option <- merged_dat$chosen_option - 1
acc <- tapply(merged_dat$chosen_option, merged_dat$id, mean)
plot(acc)
sim_data <- merged_dat
sim_data <- write.table(merged_dat, file = "ex_ante_simulation_weight_model_8blocks_30trials.txt",
row.names = FALSE, col.names = FALSE)
params_exante <- write.table(FIT, file = "ex_ante_simulation_parameters_weight_model_8blocks_30trials.txt",
row.names = FALSE, col.names = FALSE)
sim_data$chosen_option <- sim_data$chosen_option + 1
sum(sim_data$chosen_option == 2) # good option
sum(sim_data$chosen_option == 2 & sim_data$feedback == 10) # good option with positive feedback
sum(sim_data$chosen_option == 2 & sim_data$feedback == -10) # good option with negative feedback
rm(list = ls()) #delete workspace
setwd("~/Dropbox/___MA/social_RL_git/thesis_social_RL")
getwd()
library(reshape)
num = 100
subj = c(1:100)
#determine prediction of the model with best parameter estimates
cchoice      <- array(0, c(100, 8, 30))
R            <- array(0, c(100, 8, 30))
Prob         <- array(0, c(100, 8, 30))
Feed         <- array(0, c(100, 8, 30))
Feed_c       <- array(0, c(100, 8, 30))
Feed_i       <- array(0, c(100, 8, 30))
Prob_correct <- array(0, c(100, 8, 30))
PE <- Q_all  <- array(0, c(100, 8, 30))
id    <- c(1:100)
temp  <- rep(1:10, each = 10)/10
lrate <- rep(1:10, each = 1)/10
FIT <- cbind(id, lrate , temp)
for (id in subj) {
alpha <- FIT[id, 2];
beta  <- FIT[id, 3];
for (block in c(1:8)) {
Q    <- matrix(0, 1, 2) # 1 row, 4 col
PROB <- matrix(0, 1, 2)
for (trial in c(1:30)) {
for (j in c(1:2)) { # options
PROB[1, j] <- exp(beta*Q[1, j]) / (exp(beta*Q[1, 1]) + exp(beta*Q[1, 2]))
choice     <- c(j, 3-j)
P          <-   c(PROB[1, j], 1-PROB[1, j])
cchoice [id, block, trial] <- sample(choice, 1, replace = FALSE, prob = P)
}
feedback <- c(-10, 10)
if (cchoice [id, block, trial] == 2) {
rew_prob <- c(.25, .75)
R [id, block, trial] <- sample(feedback, 1, replace = FALSE, prob = rew_prob)
}
else {
rew_prob <- c(.75, .25)
R[id, block, trial] <- sample(feedback, 1, replace = FALSE, prob = rew_prob)
}
Q[1,cchoice[id,block,trial]] <- Q[1,cchoice[id,block,trial] ] + alpha * (R[id,block,trial] - Q[1,cchoice[id,block,trial]]);
#if (cchoice[id,block,trial]  == 2) {
#  Q[1,1] <- -Q[1,2];
#}
#else  {
#  Q[1,2] <- -Q[1,1]; #symmetrisches Update der Q values
#}
}
}
}
R_ <- melt(R)
C_ <- melt(cchoice)
merged_dat <- merge(C_, R_, by = c("X1", "X2", "X3"))
names(merged_dat)[1] <- "id"
names(merged_dat)[2] <- "block"
names(merged_dat)[3] <- "trial"
names(merged_dat)[4] <- "chosen_option"
names(merged_dat)[5] <- "feedback"
merged_dat$chosen_option <- merged_dat$chosen_option - 1
acc <- tapply(merged_dat$chosen_option, merged_dat$id, mean)
plot(acc)
sim_data <- merged_dat
sim_data <- write.table(merged_dat, file = "ex_ante_simulation_standard_RL_8blocks_30trials.txt",
row.names = FALSE, col.names = FALSE)
params_exante <- write.table(FIT, file = "ex_ante_simulation_parameters_standard_RL_8blocks_30trials.txt",
row.names = FALSE, col.names = FALSE)
rm(list=ls()) # delete workspace
setwd("~/Dropbox/___MA/social_RL_git/thesis_social_RL")
source("reinforce_standard.R")
library("colorspace")
#read in data
library(readr)
sim_data <- read_delim("~/Dropbox/___MA/social_RL_git/thesis_social_RL/ex_ante_simulation_standard_RL_8blocks_30trials.txt",
" ", col_names = F,
trim_ws = TRUE)
names(sim_data)[1] <- "id"
names(sim_data)[2] <- "block"
names(sim_data)[3] <- "trial"
names(sim_data)[4] <- "chosen_option"
names(sim_data)[5] <- "feedback"
library(tidyverse)
sim_data <-
sim_data %>%
arrange(id)
sim_data$chosen_option <- sim_data$chosen_option + 1
data <- sim_data
data <- as.data.frame(data)
subj = c(1:100)
FIT2 <- matrix(0, 100, 5)
#start a simplex search for finding the best parameter values
for (id in subj) {  # cycle through ids 1 to n
startParm <- c(0.1, 0.1)
names(startParm) <- c("alpha", "theta")
out <- optim(startParm, reinforce, subj = id, method = "L-BFGS-B",
lower = c(.001, .001), upper = c(1, 1), data = data)
FIT2[id, 1] <- out$value
FIT2[id, 2:3] <- out$par
print(id)
}
# determine Model comparison criterion
# BIC deviance + parameters*log(N) #N = number of trials
FIT2[, 4] <- FIT2[, 1] + 2*log(240);
# AIC: deviance + 2 * #parameters
FIT2[, 5] <- FIT2[, 1] + 2 * 2;
# sum of BIC values
sum(FIT2[, 4])
#create data frame for parameter recovery
modelfit_standard <- as.data.frame(FIT2)
names(modelfit_standard)[1] <- "LL"
names(modelfit_standard)[2] <- "alpha_fit"
names(modelfit_standard)[3] <- "beta_fit"
names(modelfit_standard)[4] <- "BIC"
names(modelfit_standard)[5] <- "AIC"
#read in parameter data from  ex ante simulation
parameter_sim <-
read_delim("~/Dropbox/___MA/social_RL_git/thesis_social_RL/ex_ante_simulation_parameters_standard_RL_8blocks_30trials.txt",
" ", col_names = F, trim_ws = TRUE)
names(parameter_sim)[1] <- "id"
names(parameter_sim)[2] <- "alpha_sim"
names(parameter_sim)[3] <- "beta_sim"
recovery_df <- cbind(modelfit_standard, parameter_sim)
corr_alpha <- cor.test(recovery_df$alpha_sim, recovery_df$alpha_fit)
recovery_alpha <-
ggplot(aes(x = alpha_sim, y = alpha_fit, color = alpha_sim), data = recovery_df) +
geom_point(size = 2, alpha = 0.6) +
geom_smooth(method = "glm", color = "darkgrey", se = F, fill = "red", alpha = 0.2) +
scale_color_gradient(low = "blue", high = "red") +
scale_y_continuous(breaks = seq(0, 1.0, 0.2)) +
scale_x_continuous(breaks = seq(0, 1.0, 0.2)) +
xlab("Simulated alpha values") +
ylab("Estimated alpha values") +
theme_classic()
corr_alpha
recovery_alpha
corr_beta
corr_beta <- cor.test(recovery_df$beta_sim, recovery_df$beta_fit)
recovery_beta <-
ggplot(aes(x = beta_sim, y = beta_fit, color = beta_sim), data = recovery_df) +
geom_point(size = 2, alpha = 0.6) +
geom_smooth(method = "glm", color = "darkgrey", se = F, fill = "red", alpha = 0.2) +
scale_color_gradient(low = "blue", high = "red") +
scale_y_continuous(breaks = seq(0, 1.0, 0.2)) +
scale_x_continuous(breaks = seq(0, 1.0, 0.2)) +
xlab("Simulated beta values") +
ylab("Estimated beta values") +
theme_classic()
corr_beta
recovery_beta
modelfit_standard <- write.table(recovery_df, file = "ex_ante_modelfit_standard_RL_8blocks_30trials.txt",
row.names = FALSE, col.names = FALSE)
rm(list = ls()) #delete workspace
setwd("~/Dropbox/___MA/social_RL_git/thesis_social_RL")
#read in ex ante fitted data
modelfit <-
read_delim("~/Dropbox/___MA/social_RL_git/thesis_social_RL/ex_ante_modelfit_standard_RL_8blocks_30trials.txt",
" ", col_names = F, trim_ws = TRUE)
names(modelfit)[1] <- "LL"
names(modelfit)[2] <- "alpha_fit"
names(modelfit)[3] <- "beta_fit"
names(modelfit)[4] <- "BIC"
names(modelfit)[5] <- "AIC"
names(modelfit)[6] <- "id"
names(modelfit)[7] <- "alpha_sim"
names(modelfit)[8] <- "beta_sim"
corr_alpha <- cor.test(modelfit$alpha_sim, modelfit$alpha_fit)
recovery_alpha <-
ggplot(aes(x = alpha_sim, y = alpha_fit, color = alpha_sim), data = modelfit) +
geom_point(size = 2, alpha = 0.6) +
geom_smooth(method = "glm", color = "darkgrey", se = F, fill = "red", alpha = 0.2) +
scale_color_gradient(low = "blue", high = "red") +
scale_y_continuous(breaks = seq(0, 1.0, 0.2)) +
scale_x_continuous(breaks = seq(0, 1.0, 0.2)) +
xlab("Simulated alpha values") +
ylab("Estimated alpha values") +
theme_classic()
corr_beta <- cor.test(modelfit$beta_sim, modelfit$beta_fit)
recovery_beta <-
ggplot(aes(x = beta_sim, y = beta_fit, color = beta_sim), data = modelfit) +
geom_point(size = 2, alpha = 0.6) +
geom_smooth(method = "glm", color = "darkgrey", se = F, fill = "red", alpha = 0.2) +
scale_color_gradient(low = "blue", high = "red") +
scale_y_continuous(breaks = seq(0, 1.0, 0.2)) +
scale_x_continuous(breaks = seq(0, 1.0, 0.2)) +
xlab("Simulated beta values") +
ylab("Estimated beta values") +
theme_classic()
corr_alpha
recovery_alpha
corr_beta
recovery_beta
rm(list = ls()) # delete workspace
setwd("~/Dropbox/___MA/social_RL_git/thesis_social_RL")
source("reinforce_2lrates.R")
#read in data
library(readr)
sim_data <- read_delim("~/Dropbox/___MA/social_RL_git/thesis_social_RL/ex_ante_simulation_2lrates_8blocks_30trials.txt",
" ", col_names = F,
trim_ws = TRUE)
names(sim_data)[1] <- "id"
names(sim_data)[2] <- "block"
names(sim_data)[3] <- "trial"
names(sim_data)[4] <- "chosen_option"
names(sim_data)[5] <- "feedback"
library(tidyverse)
sim_data <-
sim_data %>%
arrange(id)
sim_data$chosen_option <- sim_data$chosen_option + 1
data <- sim_data
data <- as.data.frame(data)
subj = c(1:125)
FIT2 <- matrix(0, 125, 6)
#start a simplex search for finding the best parameter values
for (id in subj) {  # cycle through ids 1 to n
startParm <- c(0.1, 0.1, 0.1)
names(startParm) <- c("alpha_ex", "alpha_in", "theta")
out <- optim(startParm, reinforce2lrates, subj = id, method = "L-BFGS-B",
lower = c(.001, .001, .001), upper = c(.9, .9, .9), data = data)
FIT2[id, 1] <- out$value
FIT2[id, 2:4] <- out$par
print(id)
}
#create beta distribution from which to sample weight values
z <- seq(0, 1, length = 10000)
z
test3 <- rbeta(z, 4, 4) ################## THINK THIS OVER!!
#### DISTRIBUTION SHOULB BE MORE SKEWED TO 1 AS THIS IS STANDARD RL
test3
hist(test3)
test3 <- rbeta(z, 4, 6) ################## THINK THIS OVER!!
#### DISTRIBUTION SHOULB BE MORE SKEWED TO 1 AS THIS IS STANDARD RL
test3
hist(test3)
test3 <- rbeta(z, 4, 8) ################## THINK THIS OVER!!
#### DISTRIBUTION SHOULB BE MORE SKEWED TO 1 AS THIS IS STANDARD RL
test3
hist(test3)
test3 <- rbeta(z, , 4) ################## THINK THIS OVER!!
test3 <- rbeta(z, 2, 4) ################## THINK THIS OVER!!
#### DISTRIBUTION SHOULB BE MORE SKEWED TO 1 AS THIS IS STANDARD RL
test3
hist(test3)
test3 <- rbeta(z, 6, 4) ################## THINK THIS OVER!!
#### DISTRIBUTION SHOULB BE MORE SKEWED TO 1 AS THIS IS STANDARD RL
test3
hist(test3)
test3 <- rbeta(z, 8, 4) ################## THINK THIS OVER!!
#### DISTRIBUTION SHOULB BE MORE SKEWED TO 1 AS THIS IS STANDARD RL
test3
hist(test3)
plot(test3)
#create beta distribution from which to sample weight values
z <- seq(0, 1, length = 10000)
z
test3 <- rbeta(z, 8, 4) ################## THINK THIS OVER!!
#### DISTRIBUTION SHOULB BE MORE SKEWED TO 1 AS THIS IS STANDARD RL
test3
hist(test3)
#create beta distribution from which to sample weight values
z <- seq(0, 1, length = 10000)
z
test3 <- rbeta(z, 4, 4) ################## THINK THIS OVER!!
#### DISTRIBUTION SHOULB BE MORE SKEWED TO 1 AS THIS IS STANDARD RL
test3
hist(test3)
#determine whether weight is positive or negative
d <- seq(0, 1, length = 10000)
d
test4 <- rbeta(d, 2, 2)
test4
hist(test4)
test4 <- rbeta(d, 5, 2)
test4
hist(test4)
test4 <- rbeta(d, 4, 2)
test4
hist(test4)
test4 <- rbeta(d, 4, 1)
test4
hist(test4)
test4 <- rbeta(d, 4, 2)
test4
hist(test4)
plot(test4)
#create beta distribution from which to sample weight values
z <- seq(0, 1, length = 10000)
z
test3 <- rbeta(z, 4, 4) ################## THINK THIS OVER!!
#### DISTRIBUTION SHOULB BE MORE SKEWED TO 1 AS THIS IS STANDARD RL
test3
hist(test3)
plot(test3)
#sample weight values
weight <- sample(z, 50)
#determine whether weight is positive or negative
d <- seq(0, 1, length = 10000)
d
test4 <- rbeta(d, 4, 2)
test4
hist(test4)
plot(test4)
#sample d values to determine which of the weight values is positive or negative
determ <- sample(d, 50)
sum(determ < 0.5) #check if equally many are positive or negative
determ_t <- ifelse(determ < 0.5, -1, 1) #transform all values below 0.5 to -1, all above to 1
df_sign <- as.data.frame(cbind(weight, determ_t))
weight <- df_sign$weight * df_sign$determ_t
weight_df <- as.data.frame(weight)
View(weight_df)
View(weight_df)
min(weight)
max(weight)
